{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This folder is for debugging LED, to overwrite encoder to add positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/alta/Conversational/OET/al826/2022/seq_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0046, -0.0624,  0.0081, -0.1458, -0.0070],\n",
      "        [ 0.0217, -0.0440,  0.0213, -0.0821,  0.0196]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.0657,  0.0665, -0.0143, -0.0035, -0.0443],\n",
      "        [-0.0296, -0.0099, -0.0288,  0.2861,  0.0173]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "resetting encoder positional embeddings\n",
      "tensor([[ 0.6609, -0.6226,  0.7483,  0.3327, -1.0561],\n",
      "        [ 1.1383, -0.8382, -1.3715, -0.9782,  0.9518]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.0657,  0.0665, -0.0143, -0.0035, -0.0443],\n",
      "        [-0.0296, -0.0099, -0.0288,  0.2861,  0.0173]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 0.0046, -0.0624,  0.0081, -0.1458, -0.0070],\n",
      "        [ 0.0217, -0.0440,  0.0213, -0.0821,  0.0196]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.0657,  0.0665, -0.0143, -0.0035, -0.0443],\n",
      "        [-0.0296, -0.0099, -0.0288,  0.2861,  0.0173]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "resetting encoder positional embeddings\n",
      "tensor([[ 0.2467,  0.1574,  0.2944, -1.3233, -0.1715],\n",
      "        [-0.5510,  0.8064,  1.6774,  1.5879,  0.9457]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.0657,  0.0665, -0.0143, -0.0035, -0.0443],\n",
      "        [-0.0296, -0.0099, -0.0288,  0.2861,  0.0173]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "from src.models.hugging_utils import get_transformer\n",
    "from src.models.models import TransformerHead, Seq2SeqWrapper, SequenceTransformer\n",
    "\n",
    "model = get_transformer('led')\n",
    "model = Seq2SeqWrapper.wrap(model, 2)\n",
    "model.set_setting(['reset_enc_pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c85320d9ddb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'asd' is not defined"
     ]
    }
   ],
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LEDTokenizerFast, LEDForConditionalGeneration \n",
    "\n",
    "transformer = LEDForConditionalGeneration.from_pretrained(\"allenai/led-base-16384\", return_dict=True)\n",
    "transformer.__dict__['_modules']['model'] = transformer.__dict__['_modules']['led']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.models import Seq2SeqWrapper\n",
    "model = Seq2SeqWrapper.wrap(transformer, 43)\n",
    "model.set_setting('utt_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helpers import ConvHandler, Batcher\n",
    "from src.config import config\n",
    "\n",
    "C = ConvHandler(system='led', punct=False, action=False, hes=False)\n",
    "batcher = Batcher(mode='seq2seq', num_labels=43, max_len=None, mode_args=None)\n",
    "\n",
    "test_path = f\"{config.base_dir}/data/swda/standard/test.json\"\n",
    "eval_data = C.prepare_data(path=test_path, lim=100)\n",
    "eval_convs = batcher.eval_batches(eval_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.models import Seq2SeqWrapper\n",
    "\n",
    "for batch in eval_convs:\n",
    "    output = model(input_ids=batch.ids, \n",
    "                   attention_mask=batch.mask, \n",
    "                   labels=batch.labels)\n",
    "    loss = output.loss\n",
    "    y    = output.logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = [[1,2,7,1,2,3,2,1,3,1,5,6,1],[2,2,7,1,2,3,2,1,3,1,5,6,1]]\n",
    "a = torch.Tensor(a)\n",
    "\n",
    "b = (a==1)\n",
    "c = torch.cumsum(b, -1)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.__class__.__bases__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
