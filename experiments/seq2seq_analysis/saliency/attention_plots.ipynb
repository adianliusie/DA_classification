{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook aims to run experiments to see the focus of the baseline seq2seq models for DA classification.\n",
    "\n",
    "It was hypothesised that all the encoder has all utterance seperation information, it's hard for the decoder to know what the current utterance has to be (due to complex information overload) and this notebook looks at how much focus the decoder has for each decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/alta/Conversational/OET/al826/2022/seq_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import scipy\n",
    "\n",
    "from src.eval_handler import EvalHandler\n",
    "from src.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading HPC model\n"
     ]
    }
   ],
   "source": [
    "from src.eval_handler import EvalHandler\n",
    "\n",
    "E = EvalHandler('arch/led_simple_2/', hpc=True)\n",
    "\n",
    "#E = EvalHandler('seq2seq/led_rand')\n",
    "#E = EvalHandler('seq2seq/post_encoder')\n",
    "\n",
    "eval_path = f\"{config.base_dir}/data/swda/standard/dev.json\"\n",
    "l_path = f\"{config.base_dir}/data/swda/standard/labels.json\"\n",
    "\n",
    "args = {'test_path':eval_path,\n",
    "        'bsz':1, \n",
    "        'override':False,\n",
    "        'label_path':l_path, \n",
    "        'system_args':None}\n",
    "\n",
    "args = SimpleNamespace(**args)\n",
    "\n",
    "cross_attentions = E.attention(args, conv_num=0, free=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(E.model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting average attentions over all conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 88.30it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (72,96,96) (48,96,96) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9e929647ba7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msh_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msh_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mforced_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0md3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforced_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0md3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mforced_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (72,96,96) (48,96,96) "
     ]
    }
   ],
   "source": [
    "sh_1, sh_2 = 300, 300\n",
    "\n",
    "free_output = np.zeros((72, sh_1, sh_2))\n",
    "forced_output = np.zeros((72, sh_1, sh_2))\n",
    "\n",
    "free_cache = []\n",
    "forced_cache = []\n",
    "\n",
    "for i in range(21):\n",
    "    attentions = E.attention(args, conv_num=i, free=False)[:,:sh_1,:sh_2]\n",
    "    d1, d2, d3 = attentions.shape\n",
    "    forced_output[:,:d2, :d3] = forced_output[:,:d2, :d3] + attentions\n",
    "    forced_cache.append(attentions)\n",
    "    \n",
    "    attentions = E.attention(args, conv_num=i, free=True)[:,:sh_1,:sh_2]\n",
    "    d1, d2, d3 = attentions.shape\n",
    "    free_output[:,:d2, :d3] = free_output[:,:d2, :d3] + attentions\n",
    "    free_cache.append(attentions)\n",
    "      \n",
    "row_sums = forced_output.sum(axis=-1)\n",
    "forced_attn = forced_output/row_sums[:,:,np.newaxis]\n",
    "\n",
    "row_sums = free_output.sum(axis=-1)\n",
    "free_attn = free_output/row_sums[:,:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attn in [forced_attn, free_attn]:\n",
    "    fig, ax = plt.subplots(figsize=(20,10))         # Sample figsize in inches\n",
    "    avg_attn = np.mean(attn[-12:], axis=0)\n",
    "    #avg_attn = np.mean(attn[-16:], axis=0)\n",
    "\n",
    "    avg_attn = avg_attn[:140,:140]\n",
    "    ax = sns.heatmap(avg_attn, cbar=False, square=True, vmin=0, vmax=0.1)\n",
    "\n",
    "    xticks=ax.xaxis.get_major_ticks()\n",
    "    for i in range(len(xticks)):\n",
    "        if i%5!=0:\n",
    "            xticks[i].set_visible(False)\n",
    "\n",
    "    print(avg_attn.shape)\n",
    "    ax.axline((0, 0), slope=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "for attn, cache in [(forced_attn, forced_cache), (free_attn, free_cache)]:\n",
    "    avg_attn = np.mean(attn[-12:], axis=0)\n",
    "    log_attn = np.log2(avg_attn)\n",
    "    entropy = -1*np.sum(avg_attn*log_attn, axis=1)\n",
    "    plt.plot(entropy[2:])\n",
    "    \n",
    "    if False:\n",
    "        for attn in cache[:3]:\n",
    "            avg_attn = np.mean(attn[-12:], axis=0)\n",
    "            log_attn = np.log2(avg_attn)\n",
    "            entropy = -1*np.sum(avg_attn*log_attn, axis=1)\n",
    "            plt.plot(entropy[2:], '')    \n",
    "        \n",
    "    plt.xlabel('utterance_number')\n",
    "    plt.ylabel('average entropy of weights')\n",
    "    plt.xlim(0, 140)\n",
    "    plt.ylim(1.5,6.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "for attn, cache in [(forced_attn, forced_cache), (free_attn, free_cache)]:\n",
    "    avg_attn = np.mean(attn[-12:], axis=0)\n",
    "    log_attn = np.log2(avg_attn)\n",
    "    entropy = -1*np.sum(avg_attn*log_attn, axis=1)\n",
    "    #plt.plot(entropy[2:], '--')\n",
    "    \n",
    "    if True:\n",
    "        for attn in cache[:4]:\n",
    "            avg_attn = np.mean(attn[-12:], axis=0)\n",
    "            log_attn = np.log2(avg_attn)\n",
    "            entropy = -1*np.sum(avg_attn*log_attn, axis=1)\n",
    "            plt.plot(entropy[2:])    \n",
    "        \n",
    "    plt.xlabel('utterance_number')\n",
    "    plt.ylabel('average entropy of weights')\n",
    "    plt.xlim(0, 160)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.sum(free_attn, axis=1)/300\n",
    "ax = sns.heatmap(x, cbar=False, square=False, vmin=0, vmax=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attn, cache in [(forced_attn, forced_cache), (free_attn, free_cache)]:\n",
    "    for k in range(0,6):\n",
    "        avg_attn = np.mean(attn[12*k:12*(k+1)], axis=0)\n",
    "        log_attn = np.log2(avg_attn)\n",
    "        entropy = -1*np.sum(avg_attn*log_attn, axis=1)\n",
    "        plt.plot(entropy[2:])\n",
    "        \n",
    "    plt.xlabel('utterance number')\n",
    "    plt.ylabel(r'$H(E(\\beta))$')\n",
    "    plt.xlim(0, 200)\n",
    "    plt.ylim(1.5,7.0)\n",
    "    \n",
    "    plt.legend(title='layer', labels=[i+1 for i in range(6)], loc=4)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attn, cache in [(forced_attn, forced_cache), (free_attn, free_cache)]:\n",
    "    totals = np.zeros((6,300))\n",
    "    denom = np.zeros(300)\n",
    "    for attn in cache:\n",
    "        for k in range(0,6):\n",
    "            avg_attn = np.mean(attn[12*k:12*(k+1)], axis=0)\n",
    "            log_attn = np.log2(avg_attn)\n",
    "            entropy = -1*np.sum(avg_attn*log_attn, axis=1)\n",
    "            totals[k, :len(entropy)] += entropy\n",
    "            denom[:len(entropy)] += np.ones(len(entropy))\n",
    "    \n",
    "    for line in totals/denom:\n",
    "        plt.plot(line)\n",
    "    plt.xlabel('utterance number')\n",
    "    plt.ylabel(r'$E(H(\\beta))$')\n",
    "    plt.legend(title='layer', labels=[i+1 for i in range(6)], loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
