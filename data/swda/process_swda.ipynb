{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swda_github.swda import CorpusReader\n",
    "corpus = CorpusReader('swda_github/swda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First generate label ids (in order of frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transcript 1155\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "act_labels = [utt.damsl_act_tag() for trans in corpus.iter_transcripts() for utt in trans.utterances]\n",
    "act_counter = Counter(act_labels)\n",
    "act_set, _ = zip(*act_counter.most_common())\n",
    "\n",
    "act_dict = {}\n",
    "for k, act in enumerate(act_set):\n",
    "    act_dict[act] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I've also hardcoded mapping between raw_label-id-description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'multi_segment'), (0, 'statement'), (1, 'backchannel'), (2, 'opinion'), (5, 'agreement')]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "flatten = lambda data: [utt for conv in data for utt in conv]\n",
    "\n",
    "act_pairs = [\n",
    "                ('+','multi_segment'), ('sd','statement'), ('b','backchannel'), ('sv','opinion'), ('aa','agreement'),\n",
    "                ('%','abandoned'), ('ba','appreciation'), ('qy','yes/no question'), ('x','non verbal'),  \n",
    "                ('ny','yes answers'), ('fc','closing remarks'), ('qw','wh-question'), \n",
    "                ('nn','no answers'),  ('bk','response acknowledgement'), ('h','hedge'), \n",
    "                ('qy^d','declaritive yes/no question'), ('fo_o_fw_\"_by_bc','other'), ('bh','back-channel question'), \n",
    "                ('^q','quotation'), ('bf','summarize'),('na','affermative yes/no answers'), ('ad','action-directive'), \n",
    "                ('^2','collaborative Completion'), ('b^m', 'repeat phrase'), ('qo', 'open question'), \n",
    "                ('qh', 'rhetorical question'), ('^h', 'hold before answer'), ('ar', 'reject'),\n",
    "                ('ng', 'negative non-no answers'), ('br', 'signal non understanding'), ('no', 'other answers'),\n",
    "                ('fp', 'conventional opening'), ('qrr', 'or clause'), ('arp_nd', 'dispreferred answers'), \n",
    "                ('t3', '3rd-party-talk'), ('oo_co_cc', 'offers, options'), ('t1', 'self-talk'), ('bd', 'downplayer'),\n",
    "                ('aap_am', 'maybe/accept-part'), ('^g', 'tag question'), ('qw^d', 'declarative wh-question'),\n",
    "                ('fa', 'apology'), ('ft', 'thanking')\n",
    "            ]\n",
    "\n",
    "act_names = {}\n",
    "for code, name in act_pairs:\n",
    "    act_index = act_dict[code]\n",
    "    act_names[act_index] = name\n",
    "\n",
    "print(list(act_names.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then go through datasets and get all important data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transcript 1155\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "data = []\n",
    "for trans in corpus.iter_transcripts():\n",
    "    conv_dict = {}\n",
    "    conv_dict['conv_id'] = 'sw' + str(trans.conversation_no)\n",
    "    conv = []\n",
    "    for utt in trans.utterances:\n",
    "        utt_list = utt.text_words(filter_disfluency=True)\n",
    "        utt_data = {'text':' '.join(utt_list), 'label':act_dict[utt.damsl_act_tag()], 'speaker':utt.caller}\n",
    "        conv.append(utt_data)\n",
    "    conv_dict['turns'] = conv\n",
    "    data.append(conv_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally split data into train/dev/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list(path:str)->list:\n",
    "    with open(path, 'r') as f:\n",
    "        conv_ids = f.readlines()\n",
    "        conv_ids = [i.replace('\\n', '') for i in conv_ids]\n",
    "    return conv_ids\n",
    "\n",
    "train_ids = load_list('id_splits/train_ids') \n",
    "dev_ids   = load_list('id_splits/dev_ids') \n",
    "test_ids  = load_list('id_splits/test_ids') \n",
    "\n",
    "train = [conv for conv in data if conv['conv_id'] in train_ids]\n",
    "dev   = [conv for conv in data if conv['conv_id'] in dev_ids]\n",
    "test  = [conv for conv in data if conv['conv_id'] in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115\n"
     ]
    }
   ],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_json(path, conv_dict):\n",
    "    with open(path, \"w\") as outfile:\n",
    "        json.dump(conv_dict, outfile)\n",
    "\n",
    "save_json('standard/train.json', train)\n",
    "save_json('standard/dev.json', dev)\n",
    "save_json('standard/test.json', test)\n",
    "save_json('standard/labels.json', act_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
